{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Parity Problem - RNN in Theano\n",
    "\n",
    "**Kyu Cho**  \n",
    "**11/12/2016** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application\n",
    "- Data transmission in communication systems  \n",
    "- Source: sends a bitstream to a receiver  \n",
    "- Suppose one bit gets reversed - how can we detect this?  \n",
    "- One simple way: add a parity bit to the end of each message  \n",
    "- Require that each message has even number of 1s  \n",
    "- If message has odd nmber of 1s, add a parity bit 1 to make total even  \n",
    "- If message has even number of 1s, add a parity bit 0 so total stays even  \n",
    "- Receiver checks number of 1s in traansmitted message - if it's odd -> there's aan error  \n",
    "\n",
    "# Solve it using RNN\n",
    "- Idea: keep track of some state  \n",
    "- State:  \n",
    "    + If 0 and see 1, switch to 1  \n",
    "    + If 1 and see 1, switch to 0  \n",
    "    + If see 0, keep the same state  \n",
    "\n",
    "# Example\n",
    "Input/Trget/Sequence Targets:  \n",
    "0000     0      0000  \n",
    "0001     1      0001  \n",
    "0010     1      0011  \n",
    "0011     0      0010  \n",
    "0100     1      0111  \n",
    "0101     0      0110  \n",
    "0110     0      0100  \n",
    "0111     1      0101  \n",
    "...     ....     ....  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function takes number of bits and generate all possible combinations\n",
    "def all_parity_pairs(nbit):\n",
    "    N = 2**nbit\n",
    "    remainder = 100 - (N % 100)\n",
    "    Ntotal = N + remainder\n",
    "    X = np.zeros((Ntotal, nbit))\n",
    "    Y = np.zeros(Ntotal)\n",
    "    \n",
    "    for ii in xrange(Ntotal):\n",
    "        i = ii % N\n",
    "        \n",
    "        # now generate the ith sample\n",
    "        for j in xrange(nbit):\n",
    "        \n",
    "            if i % (2**(j+1)) != 0:\n",
    "                i -= 2**j\n",
    "                X[ii,j] = 1\n",
    "        Y[ii] = X[ii].sum() % 2\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(Mi, Mo):\n",
    "    return np.random.randn(Mi, Mo) / np.sqrt(Mi + Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleRNN:\n",
    "    def __init__(self, M):\n",
    "        self.M = M # hidden layer size\n",
    "\n",
    "    def fit(self, X, Y, learning_rate=10e-1, mu=0.99, reg=1.0, activation=T.tanh, epochs=100, show_fig=False):\n",
    "        D = X[0].shape[1] # 1, X is 4100 x 12 x 1, \n",
    "        K = len(set(Y.flatten())) # 2, get the length of unquie numbers\n",
    "        N = len(Y) # 12\n",
    "        M = self.M # 4\n",
    "        self.f = activation\n",
    "\n",
    "        # initial weights\n",
    "        Wx = init_weight(D, M) # 1 x 4\n",
    "        Wh = init_weight(M, M) # 4 x 4\n",
    "        bh = np.zeros(M) # 4\n",
    "        h0 = np.zeros(M) # 4\n",
    "        Wo = init_weight(M, K) # 4 x 2\n",
    "        bo = np.zeros(K) # 2\n",
    "      \n",
    "        # make them theano shared\n",
    "        self.Wx = theano.shared(Wx)\n",
    "        self.Wh = theano.shared(Wh)\n",
    "        self.bh = theano.shared(bh)\n",
    "        self.h0 = theano.shared(h0)\n",
    "        self.Wo = theano.shared(Wo)\n",
    "        self.bo = theano.shared(bo)\n",
    "        self.params = [self.Wx, self.Wh, self.bh, self.h0, self.Wo, self.bo]\n",
    "\n",
    "        thX = T.fmatrix('X')\n",
    "        thY = T.ivector('Y')\n",
    "\n",
    "        def recurrence(x_t, h_t1):\n",
    "            h_t = self.f(x_t.dot(self.Wx) + h_t1.dot(self.Wh) + self.bh)\n",
    "            y_t = T.flatten(T.nnet.softmax(h_t.dot(self.Wo) + self.bo), outdim=1)\n",
    "            return h_t, y_t\n",
    "\n",
    "        # scan function only runs whenever thX value is filled\n",
    "        [h, y], _ = theano.scan(\n",
    "            fn = recurrence,\n",
    "            outputs_info = [self.h0, None],\n",
    "            sequences = thX, # a sequence, will go through every bit\n",
    "            n_steps = thX.shape[0],\n",
    "        )\n",
    "\n",
    "        py_x = y # (no. of bit, 1, no. of total unique number)   ex) (12, 1, 2)\n",
    "        prediction = T.argmax(py_x, axis=1) # list with len. 12 (argmax 1 returns idx. of max number in every row) \n",
    "\n",
    "        cost = -T.mean(T.log(py_x[T.arange(thY.shape[0]), thY]))\n",
    "        grads = T.grad(cost, self.params)\n",
    "        dparams = [theano.shared(p.get_value()*0) for p in self.params]\n",
    "\n",
    "        updates = [\n",
    "            (p, p + mu*dp - learning_rate*g) for p, dp, g in zip(self.params, dparams, grads)\n",
    "        ] + [\n",
    "            (dp, mu*dp - learning_rate*g) for dp, g in zip(dparams, grads)\n",
    "        ]\n",
    "\n",
    "        self.predict_op = theano.function(\n",
    "            inputs = [thX], \n",
    "            outputs = prediction\n",
    "        )\n",
    "        self.train_op = theano.function(\n",
    "            inputs = [thX, thY],\n",
    "            outputs = [cost, prediction, y],\n",
    "            updates = updates\n",
    "        )\n",
    "        \n",
    "        costs = []\n",
    "        for i in xrange(epochs):\n",
    "            X, Y = shuffle(X, Y)\n",
    "            n_correct = 0\n",
    "            cost = 0\n",
    "            \n",
    "            for j in xrange(N): # 0 to 11\n",
    "                c, p, rout = self.train_op(X[j], Y[j]) # p is index either 0 or 1\n",
    "                cost += c\n",
    "                \n",
    "                if p[-1] == Y[j,-1]: # '-1' only care about the final bit\n",
    "                    n_correct += 1\n",
    "\n",
    "            print \"y:\", rout.shape # (no. of bit, 1, no. of outputs)   ex) (12, 2)\n",
    "            print \"i:\", i, \"cost:\", cost, \"classification rate:\", (float(n_correct)/N)\n",
    "            costs.append(cost)\n",
    "\n",
    "        if show_fig:\n",
    "            plt.plot(costs)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input X: \n",
      "[[[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " ..., \n",
      " [[ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]]\n",
      "input Y: \n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [1 1 1 ..., 1 1 1]\n",
      " [0 1 1 ..., 1 1 1]\n",
      " ..., \n",
      " [1 1 1 ..., 1 1 1]\n",
      " [0 1 1 ..., 1 1 1]\n",
      " [1 0 0 ..., 0 0 0]]\n",
      "y: (12, 2)\n",
      "i: 0 cost: 2847.33660549 classification rate: 0.486585365854\n",
      "y: (12, 2)\n",
      "i: 1 cost: 2839.7526941 classification rate: 0.50243902439\n",
      "y: (12, 2)\n",
      "i: 2 cost: 2834.37458298 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 3 cost: 2831.43028268 classification rate: 0.499512195122\n",
      "y: (12, 2)\n",
      "i: 4 cost: 2829.38234907 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 5 cost: 2829.17846277 classification rate: 0.499512195122\n",
      "y: (12, 2)\n",
      "i: 6 cost: 2828.76992415 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 7 cost: 2828.1940289 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 8 cost: 2827.6280271 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 9 cost: 2827.69320134 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 10 cost: 2827.08327259 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 11 cost: 2826.61965882 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 12 cost: 2825.97690635 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 13 cost: 2825.28083338 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 14 cost: 2824.74757123 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 15 cost: 2823.8235735 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 16 cost: 2821.73067621 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 17 cost: 2820.59344621 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 18 cost: 2817.8998339 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 19 cost: 2814.42933232 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 20 cost: 2810.60825501 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 21 cost: 2804.36668959 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 22 cost: 2796.98538247 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 23 cost: 2787.12844365 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 24 cost: 2775.74218349 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 25 cost: 2762.35732735 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 26 cost: 2747.53401212 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 27 cost: 2731.67132952 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 28 cost: 2716.66976035 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 29 cost: 2702.63786496 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 30 cost: 2689.71111428 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 31 cost: 2679.26904176 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 32 cost: 2670.02080726 classification rate: 0.499268292683\n",
      "y: (12, 2)\n",
      "i: 33 cost: 2662.40910409 classification rate: 0.500975609756\n",
      "y: (12, 2)\n",
      "i: 34 cost: 2655.91087926 classification rate: 0.500731707317\n",
      "y: (12, 2)\n",
      "i: 35 cost: 2649.7039737 classification rate: 0.500243902439\n",
      "y: (12, 2)\n",
      "i: 36 cost: 2645.71121395 classification rate: 0.496829268293\n",
      "y: (12, 2)\n",
      "i: 37 cost: 2641.98393587 classification rate: 0.499268292683\n",
      "y: (12, 2)\n",
      "i: 38 cost: 2638.21354233 classification rate: 0.496585365854\n",
      "y: (12, 2)\n",
      "i: 39 cost: 2635.24772809 classification rate: 0.495609756098\n",
      "y: (12, 2)\n",
      "i: 40 cost: 2632.50223007 classification rate: 0.504146341463\n",
      "y: (12, 2)\n",
      "i: 41 cost: 2630.27998555 classification rate: 0.497804878049\n",
      "y: (12, 2)\n",
      "i: 42 cost: 2628.97848396 classification rate: 0.482195121951\n",
      "y: (12, 2)\n",
      "i: 43 cost: 2626.91337965 classification rate: 0.493414634146\n",
      "y: (12, 2)\n",
      "i: 44 cost: 2625.12523803 classification rate: 0.494146341463\n",
      "y: (12, 2)\n",
      "i: 45 cost: 2623.45704939 classification rate: 0.499268292683\n",
      "y: (12, 2)\n",
      "i: 46 cost: 2622.14804087 classification rate: 0.500975609756\n",
      "y: (12, 2)\n",
      "i: 47 cost: 2620.62462223 classification rate: 0.48243902439\n",
      "y: (12, 2)\n",
      "i: 48 cost: 2618.94054861 classification rate: 0.503414634146\n",
      "y: (12, 2)\n",
      "i: 49 cost: 2617.5883638 classification rate: 0.49243902439\n",
      "y: (12, 2)\n",
      "i: 50 cost: 2616.1828706 classification rate: 0.502926829268\n",
      "y: (12, 2)\n",
      "i: 51 cost: 2613.25672861 classification rate: 0.500731707317\n",
      "y: (12, 2)\n",
      "i: 52 cost: 2610.40113104 classification rate: 0.499756097561\n",
      "y: (12, 2)\n",
      "i: 53 cost: 2605.07157415 classification rate: 0.492926829268\n",
      "y: (12, 2)\n",
      "i: 54 cost: 2595.83485577 classification rate: 0.504146341463\n",
      "y: (12, 2)\n",
      "i: 55 cost: 2580.53910206 classification rate: 0.501951219512\n",
      "y: (12, 2)\n",
      "i: 56 cost: 2565.62453976 classification rate: 0.49512195122\n",
      "y: (12, 2)\n",
      "i: 57 cost: 2551.26376032 classification rate: 0.496097560976\n",
      "y: (12, 2)\n",
      "i: 58 cost: 2536.88584166 classification rate: 0.501951219512\n",
      "y: (12, 2)\n",
      "i: 59 cost: 2519.40619682 classification rate: 0.49487804878\n",
      "y: (12, 2)\n",
      "i: 60 cost: 2496.59939257 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 61 cost: 2468.59546451 classification rate: 0.499756097561\n",
      "y: (12, 2)\n",
      "i: 62 cost: 2435.76987825 classification rate: 0.50487804878\n",
      "y: (12, 2)\n",
      "i: 63 cost: 2408.90794889 classification rate: 0.496341463415\n",
      "y: (12, 2)\n",
      "i: 64 cost: 2388.45994259 classification rate: 0.499512195122\n",
      "y: (12, 2)\n",
      "i: 65 cost: 2370.62157648 classification rate: 0.498048780488\n",
      "y: (12, 2)\n",
      "i: 66 cost: 2352.91789496 classification rate: 0.49756097561\n",
      "y: (12, 2)\n",
      "i: 67 cost: 2335.84074828 classification rate: 0.498536585366\n",
      "y: (12, 2)\n",
      "i: 68 cost: 2316.52542774 classification rate: 0.501951219512\n",
      "y: (12, 2)\n",
      "i: 69 cost: 2295.03094423 classification rate: 0.500731707317\n",
      "y: (12, 2)\n",
      "i: 70 cost: 2271.91563661 classification rate: 0.503414634146\n",
      "y: (12, 2)\n",
      "i: 71 cost: 2247.9643773 classification rate: 0.505609756098\n",
      "y: (12, 2)\n",
      "i: 72 cost: 2225.39647469 classification rate: 0.499756097561\n",
      "y: (12, 2)\n",
      "i: 73 cost: 2203.40940232 classification rate: 0.500243902439\n",
      "y: (12, 2)\n",
      "i: 74 cost: 2179.41503653 classification rate: 0.500243902439\n",
      "y: (12, 2)\n",
      "i: 75 cost: 2146.78438339 classification rate: 0.507073170732\n",
      "y: (12, 2)\n",
      "i: 76 cost: 2100.23695229 classification rate: 0.499512195122\n",
      "y: (12, 2)\n",
      "i: 77 cost: 2044.60042414 classification rate: 0.496341463415\n",
      "y: (12, 2)\n",
      "i: 78 cost: 1992.75921657 classification rate: 0.5\n",
      "y: (12, 2)\n",
      "i: 79 cost: 1952.40921644 classification rate: 0.501463414634\n",
      "y: (12, 2)\n",
      "i: 80 cost: 1917.27545827 classification rate: 0.503170731707\n",
      "y: (12, 2)\n",
      "i: 81 cost: 1883.47531837 classification rate: 0.503658536585\n",
      "y: (12, 2)\n",
      "i: 82 cost: 1851.11581539 classification rate: 0.502682926829\n",
      "y: (12, 2)\n",
      "i: 83 cost: 1818.69250626 classification rate: 0.50243902439\n",
      "y: (12, 2)\n",
      "i: 84 cost: 1787.93210909 classification rate: 0.500975609756\n",
      "y: (12, 2)\n",
      "i: 85 cost: 1760.46352278 classification rate: 0.501219512195\n",
      "y: (12, 2)\n",
      "i: 86 cost: 1738.02784922 classification rate: 0.50512195122\n",
      "y: (12, 2)\n",
      "i: 87 cost: 1725.77877984 classification rate: 0.506341463415\n",
      "y: (12, 2)\n",
      "i: 88 cost: 1714.86886098 classification rate: 0.515365853659\n",
      "y: (12, 2)\n",
      "i: 89 cost: 1677.7994196 classification rate: 0.521463414634\n",
      "y: (12, 2)\n",
      "i: 90 cost: 1618.57368361 classification rate: 0.53\n",
      "y: (12, 2)\n",
      "i: 91 cost: 1570.57076954 classification rate: 0.537804878049\n",
      "y: (12, 2)\n",
      "i: 92 cost: 1548.94751441 classification rate: 0.542682926829\n",
      "y: (12, 2)\n",
      "i: 93 cost: 1526.49940585 classification rate: 0.545609756098\n",
      "y: (12, 2)\n",
      "i: 94 cost: 1494.92780671 classification rate: 0.561463414634\n",
      "y: (12, 2)\n",
      "i: 95 cost: 1451.33416499 classification rate: 0.58243902439\n",
      "y: (12, 2)\n",
      "i: 96 cost: 1386.74381563 classification rate: 0.617317073171\n",
      "y: (12, 2)\n",
      "i: 97 cost: 1285.815424 classification rate: 0.651463414634\n",
      "y: (12, 2)\n",
      "i: 98 cost: 1155.82915288 classification rate: 0.683902439024\n",
      "y: (12, 2)\n",
      "i: 99 cost: 343.639939945 classification rate: 0.940731707317\n",
      "y: (12, 2)\n",
      "i: 100 cost: 62.9411389213 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 101 cost: 45.0327645113 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 102 cost: 37.2868842728 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 103 cost: 32.492901565 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 104 cost: 29.0731553182 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 105 cost: 26.4456517456 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 106 cost: 24.3335109006 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 107 cost: 22.5825113344 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 108 cost: 21.0987946363 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 109 cost: 19.8198735345 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 110 cost: 18.7027775936 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 111 cost: 17.7163424018 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 112 cost: 16.8372444311 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 113 cost: 16.0477694992 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 114 cost: 15.3340411804 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 115 cost: 14.6849773851 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 116 cost: 14.0918078966 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 117 cost: 13.5471597288 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 118 cost: 13.0449947905 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 119 cost: 12.5804100389 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 120 cost: 12.1490842768 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 121 cost: 11.7474669719 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 122 cost: 11.3724407012 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 123 cost: 11.0213911681 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 124 cost: 10.6919124637 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 125 cost: 10.3821975269 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 126 cost: 10.0902955346 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 127 cost: 9.81478159481 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 128 cost: 9.55421253595 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 129 cost: 9.30741782515 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 130 cost: 9.07327473782 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 131 cost: 8.8508050561 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 132 cost: 8.6391685478 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 133 cost: 8.43758338436 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 134 cost: 8.24529381833 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 135 cost: 8.06171308836 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 136 cost: 7.88621248168 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 137 cost: 7.71828725916 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 138 cost: 7.55740628442 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 139 cost: 7.40318208495 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 140 cost: 7.2551909237 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 141 cost: 7.11301873498 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 142 cost: 6.9763733258 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 143 cost: 6.84491854821 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 144 cost: 6.71834306779 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 145 cost: 6.59640635913 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 146 cost: 6.47883264841 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 147 cost: 6.36539327847 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 148 cost: 6.25587882454 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 149 cost: 6.15008989282 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 150 cost: 6.04782642905 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 151 cost: 5.94892993667 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 152 cost: 5.8532132263 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 153 cost: 5.76054113557 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 154 cost: 5.67076504086 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 155 cost: 5.58374742135 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 156 cost: 5.49936864025 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 157 cost: 5.41750153066 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 158 cost: 5.33804705628 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 159 cost: 5.26087700983 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 160 cost: 5.18592017843 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 161 cost: 5.11305995739 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 162 cost: 5.04222716059 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 163 cost: 4.97332163381 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 164 cost: 4.90628683834 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 165 cost: 4.84102060936 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 166 cost: 4.77747171561 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 167 cost: 4.71557566199 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 168 cost: 4.6552445975 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 169 cost: 4.59645389218 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 170 cost: 4.5391123542 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 171 cost: 4.48318484491 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 172 cost: 4.4286219245 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 173 cost: 4.37536295303 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 174 cost: 4.32337092211 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 175 cost: 4.27259860993 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 176 cost: 4.22300279989 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 177 cost: 4.17453592021 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 178 cost: 4.12716884827 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 179 cost: 4.0808631021 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 180 cost: 4.03558216905 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 181 cost: 3.99128727153 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 182 cost: 3.94795966634 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 183 cost: 3.90555256604 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 184 cost: 3.86405123367 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 185 cost: 3.82341154697 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 186 cost: 3.78361483908 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 187 cost: 3.74463877969 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 188 cost: 3.70645397256 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 189 cost: 3.66903541481 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 190 cost: 3.63236243984 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 191 cost: 3.59641192133 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 192 cost: 3.56116585567 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 193 cost: 3.52659590434 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 194 cost: 3.49269236861 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 195 cost: 3.45943197476 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 196 cost: 3.42679234292 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 197 cost: 3.39476506537 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 198 cost: 3.36332383893 classification rate: 1.0\n",
      "y: (12, 2)\n",
      "i: 199 cost: 3.33245889006 classification rate: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAFkCAYAAABmeZIKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na4svZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f159c4d64d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parity(B=12, learning_rate=10e-5, epochs=200):\n",
    "    X, Y = all_parity_pairs(B)\n",
    "    N, t = X.shape\n",
    "#     print \"Input: \\n\", X[:5][:5] \n",
    "#     print \"Output: \\n\", Y[:5][:]\n",
    "#     print \"Dimention: \\n\", N, \"x\", t\n",
    "#     Input: \n",
    "#     [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "#      [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "#      [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "#      [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "#      [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
    "#     Output: \n",
    "#     [ 0.  1.  1.  0.  1.]\n",
    "#     Dimention: \n",
    "#     4100 x 12\n",
    "\n",
    "    # the loop convert single target to sequential target based on the X\n",
    "    # 1 for odd, 0 for even\n",
    "    Y_t = np.zeros(X.shape, dtype=np.int32)\n",
    "    for n in xrange(N):1\n",
    "        ones_count = 0\n",
    "        \n",
    "        for i in xrange(t):\n",
    "            \n",
    "            if X[n, i] == 1: # count all 1 in each row\n",
    "                ones_count += 1\n",
    "            \n",
    "            if ones_count % 2 == 1: # if odd, then 1\n",
    "                Y_t[n,i] = 1\n",
    "\n",
    "    X = X.reshape(N, t, 1).astype(np.float32) # rotate the matrix (4100, 12, 1)\n",
    "    print \"input X: \\n\", X\n",
    "    print \"input Y: \\n\", Y_t\n",
    "    \n",
    "    rnn = SimpleRNN(4) # 4 hidden layer size\n",
    "    rnn.fit(X, Y_t, learning_rate=learning_rate, epochs=epochs, activation=T.nnet.sigmoid, show_fig=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parity()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
