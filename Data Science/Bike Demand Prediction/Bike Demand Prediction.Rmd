---
title: "Bike Sharing Demand"
author: "Kyu Cho"
date: "October 9, 2016"
output: html_document
---
# Bike Sharing Demand

Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.

The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.

# Variables
### Independent Variables
- datetime : date and hour in "mm/dd/yyyy hh:mm" format
- season :  1=spring, 2=summer, 3=fall, 4=winter 
- holiday : whether the day is considered a holiday (1/0)
- workingday : whether the day is neither a weekend nor holiday (1/0)
- weather
    + 1=Clear, Few clouds, Partly cloudy, Partly cloudy 
    + 2=Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist 
    + 3=Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds 
    + 4=Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog 
- temp : temperature in Celsius
- atemp : "feels like" temperature in Celsius
- humidity : relative humidity
- windspeed : wind speed  

### Dependent Variables
- casual : number of non-registered user rentals initiated
- registered : number of registered user rentals initiated
- count : number of total rentals

# Table of Contents
1. Hypothesis Generation
2. Data Exploration
	+ Visualization
	+ Hypothesis Testing (using multivariate analysis)
3. Feature Engineering
4. Model Building

# Hypothesis Generation
- Hourly trend: There must be high demand during office timings. Early morning and late evening can have different trend (cyclist) and low demand during 10:00 pm to 4:00 am.
- Daily Trend: Registered users demand more bike on weekdays as compared to weekend or holiday.
- Rain: The demand of bikes will be lower on a rainy day as compared to a sunny d`ay. Similarly, higher humidity will cause to lower the demand and vice versa.
- Temperature: In India, temperature has negative correlation with bike demand. But, after looking at Washington's temperature graph, I presume it may have positive correlation.
- Pollution: If the pollution level in a city starts soaring, people may start using Bike (it may be influenced by government / company policies or increased awareness).
- Time: Total demand should have higher contribution of registered user as compared to casual because registered user base would increase over time.
Traffic: It can be positively correlated with Bike demand. Higher traffic may force people to use bike as compared to other road transport medium like car, taxi etc

# Data Exploration

```{r cache=T, warning=F, message=F}
library(mlr)

path <- getwd()
setwd(path)

train <- read.csv("train.csv")
test <- read.csv("test.csv")
```


```{r cache=T, message=F}
# make test set similiar to train set
test$registered <- 0
test$casual <- 0
test$count <- 0

# combine train and test dataset
data <- rbind(train, test)

# checking missing variables
table(is.na(data))

head(train, 2)
tail(train, 2)
head(test, 2)
tail(test, 2)
summarizeColumns(data)
```

- The dataset shows hourly rental data for two years (2011 and 2012). 
- The training data set is for the first 19 days of each month. 
- The test dataset is from 20th day to month's end. 
- We are required to predict the total count of bikes rented during each hour covered.
- In the training data set, they have separately given bike demand by registered, casual users and sum of both is given as count.
- Training data set has 12 variables (see below) and Test has 9 (excluding registered, casual and count).

## Visualization
```{r cache=T}
par(mfrow=c(4,2))
par(mar=rep(2,4))
hist(data$season)
hist(data$weather)
hist(data$humidity)
hist(data$holiday)
hist(data$workingday)
hist(data$temp)
hist(data$atemp)
hist(data$windspeed)
```

- Season has four categories of almost equal distribution
- Weather 1 has higher contribution i.e. mostly clear weather.

```{r cache=T}
round(prop.table(table(data$weather)),3)
```

- As expected, mostly working days and variable holiday is also showing a similar inference. 
- You can use the code above to look at the distribution in detail. 
- Here you can generate a variable for weekday using holiday and working day. 
- Incase, if both have zero values, then it must be a working day.
- Variables temp, atemp, humidity and windspeed  looks naturally distributed.

```{r cache=T}
# Convert discrete variables into factor (season, weather, holiday, workingday)
data$season <- as.factor(data$season)
data$weather <- as.factor(data$weather)
data$holiday <- as.factor(data$holiday)
data$workingday <- as.factor(data$workingday)
```

## Hypothesis Testing (using multivariate analysis)

```{r cache=T}
# extract 12th and 13th chrater as hour
data$hour <- substr(data$datetime, 12, 13)
data$hour <- as.factor(data$hour)

# the trend of bike demand over hours. 
boxplot(data$count ~ data$hour, xlab="hour", ylab="count of users")
```

- High       : 7-9 and 17-19 hours
- Average    : 10-16 hours
- Low        : 0-6 and 20-24 hours


```{r cache=T}
# the distribution of registered and casual users separately.
boxplot(data$registered ~ data$hour, xlab="hour", ylab="registered of users")
boxplot(data$casual ~ data$hour, xlab="hour", ylab="casual of users")
```

The registered users have similar trend as count. Whereas, casual users have different trend. 
- Thus, 'hour' is significant variable and our hypothesis is 'true'.

- There are a lot of outliers while plotting the count of registered and casual users. These values are not generated due to error, so we consider them as natural outliers.  They might be a result of groups of people taking up cycling (who are not registered).  
- To treat such outliers, use logarithm transformation.  Let's look at the similar plot after log transformation.

```{r cache=T}
boxplot(log(data$count) ~ data$hour, xlab="hour", ylab="log(count)")
```

**Daily Trend** Like Hour, we will generate a variable for day from datetime variable and after that we'll plot it

```{r cache=T}
# extract the date and days
date <- substr(data$datetime, 1, 10)
days <- weekdays(as.Date(date))
data$day <- days

boxplot(data$registered ~ data$day, xlab="day", ylab="registered of users")
boxplot(data$casual ~ data$day, xlab="day", ylab="casual of users")
```

**Rain** We don't have the 'rain' variable with us but have 'weather' which is sufficient to test our hypothesis. As per variable description, weather 3 represents light rain and weather 4 represents heavy rain. 

```{r cache=T}
boxplot(data$registered ~ data$weather, xlab="day", ylab="registered of users")
boxplot(data$casual ~ data$weather, xlab="day", ylab="casual of users")
```

It is clearly satisfying our hypothesis.

**Temperature, Windspeed and Humidity** Since these are continuous variables, use the correlation factor to validate hypothesis.

```{r cache=T}
library(corrplot)
# Pick only few continous variables 
cont_names <- c("registered", "casual", "count", "temp", "humidity", "atemp", "windspeed")
sub <- cor(data[, names(data) %in% cont_names])

cor.mtest <- function(mat, conf.level=0.95){
  mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n)
    diag(p.mat) <- 0
    diag(lowCI.mat) <- diag(uppCI.mat) <- 1
    for(i in 1:(n-1)){
        for(j in (i+1):n){
            tmp <- cor.test(mat[,i], mat[,j], conf.level=conf.level)
            p.mat[i,j] <- p.mat[j,i] <- tmp$p.value
            lowCI.mat[i,j] <- lowCI.mat[j,i] <- tmp$conf.int[1]
            uppCI.mat[i,j] <- uppCI.mat[j,i] <- tmp$conf.int[2]
        }
    }
    return(list(p.mat, lowCI.mat, uppCI.mat))
}

res1 <- cor.mtest(sub,0.95)
res2 <- cor.mtest(sub,0.99)

## specialized the insignificant value according to the significant level
M <- cor(sub)
corrplot(M, p.mat=res1[[1]], sig.level=0.2)
```

- 'Variable' temp is positively correlated with dependent variables (casual is more compare to registered)
- 'atemp' is highly correlated with temp.
- 'Windspeed' has lower correlation as compared to temp and humidity


**Time** Extract year of each observation from the datetime column and see the trend of bike demand over year.

```{r cache=T}
data$year <- substr(data$datetime, 1, 4)
data$year <- as.factor(data$year)

boxplot(data$count ~ data$year, xlab="year", ylab="count")
```

2012 has higher bike demand as compared to 2011.

**Pollution & Traffic**  We don't have the variable related with these metrics in our data set so we cannot test this hypothesis.

# Feature Engineering

**Hour Bins** Create bins for the hour variable separately for casual and registered users. Here we will use decision tree to find the accurate bins.

```{r cache=T, warning=F}
library(rpart)
library(rattle) 
library(rpart.plot)
library(RColorBrewer)

# convert hour to integer
data$hour <- as.integer(data$hour)
```

```{r cache=T}
# Bin: registered and hour
d <- rpart(registered ~ hour, data=data)
fancyRpartPlot(d)

data$dp_reg <- 0
data$dp_reg[data$hour < 8] <- 1
data$dp_reg[data$hour >= 22] <- 2
data$dp_reg[data$hour > 9 & data$hour < 18] <- 3
data$dp_reg[data$hour == 8] <- 4
data$dp_reg[data$hour == 9] <- 5
data$dp_reg[data$hour == 20 | data$hour == 21] <- 6
data$dp_reg[data$hour == 19 | data$hour == 18] <- 7

# Bin: cacual and hour
d <- rpart(casual ~ hour, data=data)
fancyRpartPlot(d)

data$dp_cas <- 0
data$dp_cas[data$hour < 10] <- 1
data$dp_cas[data$hour >= 20 & data$hour >= 10] <- 2
data$dp_cas[data$hour < 21 & data$hour >= 10] <- 3
```


**Temp Bins** Create bins for temperature for both registered and casuals users. Variables created are (temp_reg and temp_cas).

```{r cache=T}
# Bin: registered and temp
d <- rpart(registered ~ temp, data=data)
fancyRpartPlot(d)

data$temp_reg <- 0
data$temp_reg[data$temp < 14] <- 1
data$temp_reg[data$temp < 28 & data$temp >= 14] <- 2
data$temp_reg[data$temp >= 28] <- 3

# Bin: registered and temp
d <- rpart(casual ~ temp, data=data)
fancyRpartPlot(d)

data$casual <- 0
data$casual[data$temp < 20] <- 1
data$casual[data$temp < 29 & data$temp >= 20] <- 2
data$casual[data$temp >= 29] <- 3
```

**Year Bins** Create 8 bins (quarterly) for two years. Jan-Mar 2011 as 1 and Oct-Dec2012 as 8, sicne a hypothesis that bike demand will increase over time is vertified.

```{r cache=T}
data$month <- as.numeric(substr(data$datetime, 6, 7))
data$year_part[data$year == '2011'] <- 1
data$year_part[data$year == '2011' & data$month > 3] <- 2
data$year_part[data$year == '2011' & data$month > 6] <- 3
data$year_part[data$year == '2011' & data$month > 9] <- 4
data$year_part[data$year == '2012'] <- 5
data$year_part[data$year == '2012' & data$month > 3] <- 6
data$year_part[data$year == '2012' & data$month > 6] <- 7
data$year_part[data$year == '2012' & data$month > 9] <- 8
table(data$year_part)
```

**Day Type** Create a variable having categories like "weekday", "weekend" and "holiday".

```{r cache=T}
data$day_type <- ""
data$day_type[data$holiday == 0 & data$workingday == 0] <- "weekend"
data$day_type[data$holiday == 1] <- "holiday"
data$day_type[data$holiday == 0 & data$workingday == 1] <- "working day"
table(data$day_type)
```

**Weekend** Created a separate variable for weekend (0/1)

```{r cache=T}
data$weekend <- 0
data$weekend[data$day == "Sunday" | data$day == "Saturday" ] <- 1
```

# Model Building

- Predict log of dependent variables; since, Dependent variables have natural outliers. 
- Predict bike demand registered and casual users separately.
- y1 = log(casual + 1) and y2 = log(registered + 1)
    + Adding 1 to deal with zero values in the casual and registered columns
    
```{r cache=T}
data$logreg <- log(data$registered + 1) 
data$logcas <- log(data$casual + 1) 
data$hour <- as.factor(data$hour)

# Spliting data set in to train and test again
train <- head(data, nrow(train))
test <- tail(data, nrow(test))
```


    
```{r cache=T, results="hide", warning=F}
library(randomForest)
set.seed(111)
reg_rf <- randomForest(logreg ~ hour + dp_reg + workingday + holiday + temp_reg + windspeed + season + weather + weekend + year + year_part, 
                     data=train, importance=TRUE, ntree=25)
pred_reg_rf <- predict(reg_rf, test)
test$logreg <- pred_reg_rf

cas_rf <- randomForest(logcas ~ hour + dp_reg + workingday + holiday + temp_reg + windspeed + season + weather + weekend + year + year_part, 
                     data=train, importance=TRUE, ntree=25)
pred_cas_rf <- predict(cas_rf, test)
test$logcas <- pred_cas_rf
```


Re-transforming the predicted variables and then writing the output of count to the file submit.csv

```{r cache=T}
test$registered <- exp(test$logreg) - 1
test$casual <- exp(test$logcas) - 1
test$count <- test$casual + test$registered
s <- data.frame(datetime=test$datetime, count=test$count)
write.csv(s,file="submit.csv",row.names=FALSE)
```

- Score 0.3573 on Kaggle leaderboard i.e. top 5 percentile of total participants. 
- Structured approach of problem solving improves performance. 
- Generating hypothesis before dive in the data set as this technique will not limit the thought process.

TODO:
    + apply advanced techniques (or ensemble methods) 



